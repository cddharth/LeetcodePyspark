{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "719ed16f-bc77-4ab9-8e50-9a3e5675970b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2dab3e2-eb52-4ca8-baf9-4676e501c1cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7430c1d5-a1fd-48a7-a749-8a6d017fab15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 175. Combine Two Tables\n",
    "\n",
    "Write a solution to report the first name, last name, city, and state of each person in the Person table. If the address of a personId is not present in the Address table, report null instead.\n",
    "\n",
    "Return the result table in any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58612694-df52-4796-8e52-c2aeebc9c3e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema for Person table\n",
    "person_schema = StructType([\n",
    "    StructField(\"personId\", IntegerType(), True),\n",
    "    StructField(\"lastName\", StringType(), True),\n",
    "    StructField(\"firstName\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create Person DataFrame\n",
    "data_person = [\n",
    "    (1, \"Wang\", \"Allen\"),\n",
    "    (2, \"Alice\", \"Bob\")\n",
    "]\n",
    "\n",
    "df_person = spark.createDataFrame(data_person, schema=person_schema)\n",
    "df_person.show()\n",
    "\n",
    "# Define schema for Address table\n",
    "address_schema = StructType([\n",
    "    StructField(\"addressId\", IntegerType(), True),\n",
    "    StructField(\"personId\", IntegerType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create Address DataFrame\n",
    "data_address = [\n",
    "    (1, 2, \"New York City\", \"New York\"),\n",
    "    (2, 3, \"Leetcode\", \"California\")\n",
    "]\n",
    "\n",
    "df_address = spark.createDataFrame(data_address, schema=address_schema)\n",
    "df_address.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81a5c1d4-b094-49c2-a3ca-26b561514577",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_person.join(\n",
    "    df_address, df_person['personId'] == df_address['personId'], 'left')\\\n",
    "        .select([\"lastName\", \"firstName\", \"city\", \"state\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32697cc8-9e41-447d-a6fb-958b1ffd34cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pandas\n",
    "pdf_address = df_address.toPandas()\n",
    "pdf_person = df_person.toPandas()\n",
    "pdf_address.display()\n",
    "pdf_person.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0ed2903-71d7-4063-9858-36ddb12c9448",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_person.merge(pdf_address, on='personId', how = 'left')[['lastName', 'firstName', 'city', 'state']].display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7852ff4-058d-4141-b394-a8f33b61d21a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 181. Employees Earning More Than Their Managers\n",
    "id is the primary key (column with unique values) for this table.\n",
    "Each row of this table indicates the ID of an employee, their name, salary, and the ID of their manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8ad7ea8-368f-45d1-8e10-9f030e6f8884",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema for Employee table\n",
    "employee_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True),\n",
    "    StructField(\"managerId\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create Employee DataFrame\n",
    "data_employee = [\n",
    "    (1, \"Joe\", 70000, 3),\n",
    "    (2, \"Henry\", 80000, 4),\n",
    "    (3, \"Sam\", 60000, None),\n",
    "    (4, \"Max\", 90000, None)\n",
    "]\n",
    "\n",
    "df_employee1 = spark.createDataFrame(data_employee, schema=employee_schema)\n",
    "df_employee2 = spark.createDataFrame(data_employee, schema=employee_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44168b6f-b52c-4c49-933a-ce449d765c80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_employee1.show()\n",
    "df_employee2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a67666b6-00aa-44a6-b203-cae8590fe4a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_employee1.join(df_employee2, df_employee1.id == df_employee2.managerId, 'inner')\\\n",
    "    .select(df_employee2[\"name\"]).filter(df_employee2[\"salary\"] > df_employee1[\"salary\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07d0e531-f13f-48ae-8927-7ee105e494b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pandas\n",
    "\n",
    "pdf_employee = df_employee1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7653bd40-2b68-4629-9793-7450bdc803de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_merge = pdf_employee.merge(pdf_employee, left_on = 'managerId', right_on = 'id', how = 'left' ).iloc[:,[1,2,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d6dcab7-ec53-4bfb-ab54-9c00f4993e96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_merge.loc[pdf_merge['salary_x'] > pdf_merge['salary_y']].iloc[:,[0]].display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0936d0db-a08b-42a5-8d00-25ff80534424",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 182. Duplicate Emails\n",
    "Write a solution to report all the duplicate emails. Note that it's guaranteed that the email field is not NULL.\n",
    "\n",
    "Return the result table in any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98cb5882-b8ef-4858-8141-101b83035735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema for Email table\n",
    "email_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"email\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create Email DataFrame\n",
    "data_email = [\n",
    "    (1, \"a@b.com\"),\n",
    "    (2, \"c@d.com\"),\n",
    "    (3, \"a@b.com\")\n",
    "]\n",
    "\n",
    "df_email = spark.createDataFrame(data_email, schema=email_schema)\n",
    "df_email.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3a3543d-656f-4f82-b2f2-56cea0441fb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_email.groupby(\"email\").count().filter(\"count > 1\").select(\"email\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f711d454-89dc-42fc-ad15-f4053e5e6d8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_email = df_email.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c427b2e-7187-4338-bc4a-b950c38d78c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_email = pdf_email.groupby(\"email\").count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a553020-107a-44b7-a3a2-ce41c3492c9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_email.loc[pdf_email['id'] > 1].iloc[:,[0]].display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69c69140-f89a-4b8e-ab4d-d27f1697ce5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 183. Customers Who Never Order\n",
    "Write a solution to find all customers who never order anything.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bbf25eb-bac5-4581-ad35-fdfa7e187b2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema for Customers table\n",
    "customers_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create Customers DataFrame\n",
    "data_customers = [\n",
    "    (1, \"Joe\"),\n",
    "    (2, \"Henry\"),\n",
    "    (3, \"Sam\"),\n",
    "    (4, \"Max\")\n",
    "]\n",
    "\n",
    "df_customers = spark.createDataFrame(data_customers, schema=customers_schema)\n",
    "df_customers.show()\n",
    "\n",
    "# Define schema for Orders table\n",
    "orders_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"customerId\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create Orders DataFrame\n",
    "data_orders = [\n",
    "    (1, 3),\n",
    "    (2, 1)\n",
    "]\n",
    "\n",
    "df_orders = spark.createDataFrame(data_orders, schema=orders_schema)\n",
    "df_orders.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "546a0737-d865-4894-8315-9341a1ba11c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_customers.join(df_orders, df_customers.id == df_orders.customerId, 'anti')\\\n",
    "    .select('name').alias('Customers').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc9a7712-9481-4fa5-ab8e-a616bc5ae368",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_customers = df_customers.toPandas()\n",
    "pdf_orders = df_orders.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fde94ffb-4f8f-40c5-83b1-5a93b1ff82f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_customers.display()\n",
    "pdf_orders.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6d7ca0c-f4f7-4639-9749-14d42f7fac57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_customers = pdf_customers.merge(pdf_orders, left_on = 'id', right_on = 'customerId', how = 'left')\n",
    "pdf_customers.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44e1209d-03ae-44a1-b90c-140c0d5d0f9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_customers.loc[pd.isnull(pdf_customers['id_y']), ['name']].display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "367f3769-5a99-4eb7-bb8d-b007ff2f4916",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 176. Second Highest Salary\n",
    "Write a solution to find the second highest distinct salary from the Employee table. If there is no second highest salary, return null (return None in Pandas).\n",
    "\n",
    "The result format is in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "914700aa-5409-428f-8e46-8af97d82717a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema for simple Employee salary table\n",
    "simple_employee_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create simple Employee DataFrame\n",
    "data_simple_employee = [\n",
    "    (1, 100),\n",
    "    (2, 200),\n",
    "    (3, 300)\n",
    "]\n",
    "\n",
    "df_simple_employee = spark.createDataFrame(data_simple_employee, schema=simple_employee_schema)\n",
    "df_simple_employee.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdae3065-a23d-405d-8cba-05d03563fb09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "window_spec = Window.orderBy(col(\"salary\").desc())\n",
    "df_win = df_simple_employee.withColumn('rank', dense_rank().over(window_spec))\n",
    "df_filtered = df_win.select(df_win['salary']).filter(df_win[\"rank\"] == 2)\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31c09f8e-976f-4064-b42d-0d732b27f30c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_sim_emp = df_simple_employee.toPandas()\n",
    "pdf_sim_emp.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5537d9cb-a366-433b-8ac8-36118b4a70e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_sim_emp['rank'] = pdf_sim_emp['salary'].rank(method = 'dense', ascending = 'True')\n",
    "pdf_sim_emp.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fdc9505-ce48-4f30-a0e4-01a7a23dba7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_sim_emp.loc[pdf_sim_emp['rank'] == 2, ['salary']].display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a37c2a0f-648c-4314-9186-dbf0bec7a19a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 184. Department Highest Salary\n",
    "Write a solution to find employees who have the highest salary in each of the departments.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ec40c1-b939-48cc-a430-1268348367d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema for Employee table\n",
    "employee_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True),\n",
    "    StructField(\"departmentId\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create Employee DataFrame\n",
    "employee = [\n",
    "    (1, \"Joe\", 70000, 1),\n",
    "    (2, \"Jim\", 90000, 1),\n",
    "    (3, \"Henry\", 80000, 2),\n",
    "    (4, \"Sam\", 60000, 2),\n",
    "    (5, \"Max\", 90000, 1)\n",
    "]\n",
    "\n",
    "df_employee = spark.createDataFrame(employee, schema=employee_schema)\n",
    "df_employee.show()\n",
    "\n",
    "# Define schema for Department table\n",
    "department_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create Department DataFrame\n",
    "data_department = [\n",
    "    (1, \"IT\"),\n",
    "    (2, \"Sales\")\n",
    "]\n",
    "\n",
    "df_department = spark.createDataFrame(data_department, schema=department_schema)\n",
    "df_department.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01cf6090-f765-49b1-8e77-3a0e0eb03964",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df_joined = df_employee.join(\n",
    "    df_department,\n",
    "    df_employee.departmentId == df_department.id,\n",
    "    'inner'\n",
    ")\n",
    "\n",
    "df_selected = df_joined.select(\n",
    "    df_employee['name'].alias('employee_name'),\n",
    "    df_employee['salary'],\n",
    "    df_employee['departmentId'],\n",
    "    df_department['name'].alias('departmentname')\n",
    ")\n",
    "\n",
    "display(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd956886-e6dd-4fff-a176-aee31629f16f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_group = df_selected.groupBy('departmentname').agg(max('salary').alias('salary'))\n",
    "\n",
    "df_selected.select(['employee_name', 'salary', 'departmentname']).join(df_group, df_selected.salary == df_group.salary, 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e5e27aa-a06c-4d42-8764-64518dcf8e3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_employee = df_employee.toPandas()\n",
    "pdf_department = df_department.toPandas()\n",
    "pdf_merge = pdf_employee.merge(pdf_department, left_on='departmentId', right_on = 'id', how = 'left').iloc[:, [1,2,5]]\n",
    "print(pdf_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "668f5652-38d0-44f8-93bf-5dafae832c58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "maxsal = pdf_merge.groupby('name_y')['salary'].idxmax()\n",
    "display(maxsal)\n",
    "result = pdf_merge.loc[maxsal, ['name_y', 'salary']]\n",
    "result = result.reset_index(drop=True)\n",
    "display(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34cb0a1a-6443-4c73-9ae0-d36c2137a27b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_employee.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6cea74f-ff9f-4e90-972e-bfd0f919c358",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_employee.join(result, left_on = 'salary', right_on = 'salary', how= 'left' ).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88da2c54-2143-404d-9ea2-9de02b39b177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 196. Delete Duplicate Emails\n",
    "Write a solution to delete all duplicate emails, keeping only one unique email with the smallest id.\n",
    "\n",
    "For SQL users, please note that you are supposed to write a DELETE statement and not a SELECT one.\n",
    "\n",
    "For Pandas users, please note that you are supposed to modify Person in place.\n",
    "\n",
    "After running your script, the answer shown is the Person table. The driver will first compile and run your piece of code and then show the Person table. The final order of the Person table does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31bf0b0c-8b29-4d12-b7ae-c80b32baf2b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema\n",
    "person_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"email\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "data_person = [\n",
    "    (1, \"john@example.com\"),\n",
    "    (2, \"bob@example.com\"),\n",
    "    (3, \"john@example.com\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_person = spark.createDataFrame(data_person, schema=person_schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df_person.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "435db13d-c091-41f8-b0f7-7b605e662580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_person.drop_duplicates(['email']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27b14a9f-19c5-4d06-9de1-2c20b7d4f300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 197. Rising Temperature\n",
    "Write a solution to find all dates' id with higher temperatures compared to its previous dates (yesterday).\n",
    "\n",
    "Return the result table in any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1541067e-2366-4dd4-853c-01c2b50edef6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import *\n",
    "\n",
    "# Define schema\n",
    "weather_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"recordDate\", DateType(), True),\n",
    "    StructField(\"temperature\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Sample data with proper datetime conversion\n",
    "data_weather = [\n",
    "    (1, datetime.strptime(\"2015-01-01\", \"%Y-%m-%d\").date(), 10),\n",
    "    (2, datetime.strptime(\"2015-01-02\", \"%Y-%m-%d\").date(), 25),\n",
    "    (3, datetime.strptime(\"2015-01-03\", \"%Y-%m-%d\").date(), 20),\n",
    "    (4, datetime.strptime(\"2015-01-04\", \"%Y-%m-%d\").date(), 30)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_weather = spark.createDataFrame(data_weather, schema=weather_schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df_weather.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4c9de41-ace4-4ce7-988b-f640e6efd8e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "window_spec = Window.orderBy('recordDate')\n",
    "df_result = df_weather.withColumn('prevtemp', lag('temperature').over(window_spec))\n",
    "df_result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24006d53-bd83-470e-80b4-8bb26a61abe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_result.select('id').filter(df_result['temperature'] > df_result['prevtemp']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9612119-8281-462c-bfa3-d7268d8fb8c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 511. Game Play Analysis I\n",
    "\n",
    "Input: \n",
    "Activity table:\n",
    "+-----------+-----------+------------+--------------+\n",
    "| player_id | device_id | event_date | games_played |\n",
    "+-----------+-----------+------------+--------------+\n",
    "| 1         | 2         | 2016-03-01 | 5            |\n",
    "| 1         | 2         | 2016-05-02 | 6            |\n",
    "| 2         | 3         | 2017-06-25 | 1            |\n",
    "| 3         | 1         | 2016-03-02 | 0            |\n",
    "| 3         | 4         | 2018-07-03 | 5            |\n",
    "+-----------+-----------+------------+--------------+\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Output: \n",
    "+-----------+-------------+\n",
    "| player_id | first_login |\n",
    "+-----------+-------------+\n",
    "| 1         | 2016-03-01  |\n",
    "| 2         | 2017-06-25  |\n",
    "| 3         | 2016-03-02  |\n",
    "+-----------+-------------+\n",
    "\n",
    "\n",
    "\n",
    "Write a solution to find the first login date for each player.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "451e5ad5-8738-490c-bbab-8b4474864d99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f868c754-664c-4062-ba5f-afeff291d2a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"player_id\", IntegerType(), False),\n",
    "    StructField(\"device_id\", IntegerType(), False),\n",
    "    StructField(\"event_date\", DateType(), False),\n",
    "    StructField(\"games_played\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "# Create data\n",
    "data = [\n",
    "    (1, 2, datetime.strptime(\"2016-03-01\", \"%Y-%m-%d\").date(), 5),\n",
    "    (1, 2, datetime.strptime(\"2016-05-02\", \"%Y-%m-%d\").date(), 6),\n",
    "    (2, 3, datetime.strptime(\"2017-06-25\", \"%Y-%m-%d\").date(), 1),\n",
    "    (3, 1, datetime.strptime(\"2016-03-02\", \"%Y-%m-%d\").date(), 0),\n",
    "    (3, 4, datetime.strptime(\"2018-07-03\", \"%Y-%m-%d\").date(), 5)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9ae51c9-976e-4463-a6b8-928284a09deb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df_game = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df_game.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d41c031-932e-435f-a7fa-185e654e4ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_game.select('player_id', 'event_date').groupBy('player_id').agg(min('event_date').alias('first_login')).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6a9a188-c4fa-4860-bcd9-f01a882b4431",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pandas\n",
    "pdf_game = df_game.toPandas()\n",
    "display(pdf_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4b7e0b4-1f9d-4a39-8929-07d5c1dc687a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_game.groupby('player_id')['event_date'].min().reset_index().display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5c77111-2ead-4021-a22f-0ccaaf4b50f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 577. Employee Bonus\n",
    "\n",
    "Write a solution to report the name and bonus amount of each employee with a bonus less than 1000.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    "Input: \n",
    "Employee table:\n",
    "| empId | name   | supervisor | salary |\n",
    "|-------|--------|------------|--------|\n",
    "| 3     | Brad   | null       | 4000   |\n",
    "| 1     | John   | 3          | 1000   |\n",
    "| 2     | Dan    | 3          | 2000   |\n",
    "| 4     | Thomas | 3          | 4000   |\n",
    "\n",
    "### Bonus Table:\n",
    "| empId | bonus |\n",
    "|-------|-------|\n",
    "| 2     | 500   |\n",
    "| 4     | 2000  |\n",
    "\n",
    "### Output Table:\n",
    "| name  | bonus |\n",
    "|-------|-------|\n",
    "| Brad  | null  |\n",
    "| John  | null  |\n",
    "| Dan   | 500   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbd67206-0c61-4897-9b16-368d8634d7e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Employee Table Schema\n",
    "employee_schema = StructType([\n",
    "    StructField(\"empId\", IntegerType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"supervisor\", IntegerType(), True),  # Nullable\n",
    "    StructField(\"salary\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "# Employee Table Data\n",
    "employee_data = [\n",
    "    (3, \"Brad\", None, 4000),\n",
    "    (1, \"John\", 3, 1000),\n",
    "    (2, \"Dan\", 3, 2000),\n",
    "    (4, \"Thomas\", 3, 4000)\n",
    "]\n",
    "\n",
    "# Create Employee DataFrame\n",
    "df_employee = spark.createDataFrame(employee_data, schema=employee_schema)\n",
    "df_employee.show()\n",
    "\n",
    "# 2. Bonus Table Schema\n",
    "bonus_schema = StructType([\n",
    "    StructField(\"empId\", IntegerType(), False),\n",
    "    StructField(\"bonus\", IntegerType(), True)  # Nullable\n",
    "])\n",
    "\n",
    "# Bonus Table Data\n",
    "bonus_data = [\n",
    "    (2, 500),\n",
    "    (4, 2000)\n",
    "]\n",
    "\n",
    "# Create Bonus DataFrame\n",
    "df_bonus = spark.createDataFrame(bonus_data, schema=bonus_schema)\n",
    "df_bonus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e0a17ee-8aeb-403a-9ab7-e24479fd013a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_group = df_employee.join(df_bonus, df_employee.empId == df_bonus.empId, 'left')\\\n",
    "    .select('name', 'bonus')\n",
    "df_group.filter((df_group['bonus'] < 1000) | (df_group['bonus'].isNull())).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55f9719a-e475-459b-ab3e-609c03400228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Pandas\n",
    "\n",
    "pdf_employee = df_employee.toPandas()\n",
    "pdf_employee.display()\n",
    "pdf_bonus = df_bonus.toPandas()\n",
    "pdf_bonus.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e571753-d5e1-4a8b-8896-bbc896c30a2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_merge = pdf_employee.merge(pdf_bonus, on = 'empId', how = 'left').iloc[:, [1,4]]\n",
    "pdf_merge.loc[(pdf_merge['bonus'] < 1000) | (pdf_merge['bonus'].isnull())].display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1a64c75-9de9-4777-84e3-cb35c2d48301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 584. Find Customer Referee\n",
    "\n",
    "Find the names of the customer that are not referred by the customer with id = 2.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    "### Input: Customer Table\n",
    "| id | name | referee_id |\n",
    "|----|------|------------|\n",
    "| 1  | Will | null       |\n",
    "| 2  | Jane | null       |\n",
    "| 3  | Alex | 2          |\n",
    "| 4  | Bill | null       |\n",
    "| 5  | Zack | 1          |\n",
    "| 6  | Mark | 2          |\n",
    "\n",
    "### Output:\n",
    "| name |\n",
    "|------|\n",
    "| Will |\n",
    "| Jane |\n",
    "| Bill |\n",
    "| Zack |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82a6a9ef-a079-4909-a10e-45f3869c6b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Schema for Customer Table\n",
    "customer_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"referee_id\", IntegerType(), True)  # Nullable\n",
    "])\n",
    "\n",
    "# Data for Customer Table\n",
    "customer_data = [\n",
    "    (1, \"Will\", None),\n",
    "    (2, \"Jane\", None),\n",
    "    (3, \"Alex\", 2),\n",
    "    (4, \"Bill\", None),\n",
    "    (5, \"Zack\", 1),\n",
    "    (6, \"Mark\", 2)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_customer = spark.createDataFrame(customer_data, schema=customer_schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df_customer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52b5a045-093d-4f0d-bb58-a82282bad838",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_customer.select('name').filter((df_customer['referee_id'] != 2) | (df_customer['referee_id'].isNull())).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abb04743-f627-45ab-bfd7-6bfb2a7418e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pandas\n",
    "pdf_customer = df_customer.toPandas()\n",
    "pdf_customer['name'][(pdf_customer['referee_id'] != 2) | (pdf_customer['referee_id'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0069e8a0-e7eb-4a15-9de0-3f057a890515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 620. Not Boring Movies\n",
    "\n",
    "Write a solution to report the movies with an odd-numbered ID and a description that is not \"boring\".\n",
    "\n",
    "Return the result table ordered by rating in descending order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    "##### **Input** -\n",
    "Cinema table\n",
    "\n",
    "| id | movie      | description | rating |\n",
    "|----|-----------|-------------|--------|\n",
    "| 1  | War       | great 3D    | 8.9    |\n",
    "| 2  | Science   | fiction     | 8.5    |\n",
    "| 3  | irish     | boring      | 6.2    |\n",
    "| 4  | Ice song  | Fantacy     | 8.6    |\n",
    "| 5  | House card| Interesting | 9.1    |\n",
    "\n",
    "\n",
    "##### **Output Table** -\n",
    "\n",
    "| id | movie      | description | rating |\n",
    "|----|-----------|-------------|--------|\n",
    "| 5  | House card| Interesting | 9.1    |\n",
    "| 1  | War       | great 3D    | 8.9    |\n",
    "\n",
    "**Explanation**: \n",
    "We have three movies with odd-numbered IDs: 1, 3, and 5. The movie with ID = 3 is boring so we do not include it in the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9254d9f4-2942-43c7-bd6a-fdba987f5ed9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "461419d7-7a86-4704-81ed-4122831f33d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Schema with DecimalType (Precision 3, Scale 1)\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"movie\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"rating\", DecimalType(4, 1), True)  # Precision 4, Scale 1 (e.g., 9.1)\n",
    "])\n",
    "\n",
    "# Ensure Float Values are Converted to Decimal\n",
    "data = [\n",
    "    (1, \"War\", \"great 3D\", Decimal(\"8.9\")),\n",
    "    (2, \"Science\", \"fiction\", Decimal(\"8.5\")),\n",
    "    (3, \"irish\", \"boring\", Decimal(\"6.2\")),\n",
    "    (4, \"Ice song\", \"Fantacy\", Decimal(\"8.6\")),\n",
    "    (5, \"House card\", \"Interesting\", Decimal(\"9.1\"))\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_cinema = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df_cinema.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee0b7e77-65ea-4efb-a4ff-daf9215b5b5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_cinema.filter((col('description') != 'boring') & (col('id') % 2 == 1)) \\\n",
    "    .orderBy(col('rating'), ascending=False)\\\n",
    "         .display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d625835-787a-4a67-b788-9e91cea1c84e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_cinema = df_cinema.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a8fcb6e-0376-45b9-bd61-d64146ca5b3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_cinema.loc[(pdf_cinema['description'] != 'boring') & (pdf_cinema['id'] % 2 == 1)].sort_values(by = 'rating', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c911d121-3af3-4f65-b654-560dcc6f9531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 627 Swap Salary\n",
    "Write a solution to swap all 'f' and 'm' values (i.e., change all 'f' values to 'm' and vice versa) with a single update statement and no intermediate temporary tables.\n",
    "Note that you must write a single update statement, do not write any select statement for this problem.\n",
    "The result format is in the following example.\n",
    "\n",
    "### Input: Salary Table\n",
    "| id | name | sex | salary |\n",
    "|----|------|-----|--------|\n",
    "| 1  | A    | m   | 2500   |\n",
    "| 2  | B    | f   | 1500   |\n",
    "| 3  | C    | m   | 5500   |\n",
    "| 4  | D    | f   | 500    |\n",
    "\n",
    "### Output: Salary Table (Swapped Sex Column)\n",
    "| id | name | sex | salary |\n",
    "|----|------|-----|--------|\n",
    "| 1  | A    | f   | 2500   |\n",
    "| 2  | B    | m   | 1500   |\n",
    "| 3  | C    | f   | 5500   |\n",
    "| 4  | D    | m   | 500    |\n",
    "\n",
    "\n",
    "Explanation: \n",
    "(1, A) and (3, C) were changed from 'm' to 'f'.\n",
    "(2, B) and (4, D) were changed from 'f' to 'm'.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16039790-c2e0-4ce7-add4-88e4333f2054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create Data\n",
    "data = [\n",
    "    (1, \"A\", \"m\", 2500),\n",
    "    (2, \"B\", \"f\", 1500),\n",
    "    (3, \"C\", \"m\", 5500),\n",
    "    (4, \"D\", \"f\", 500)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_salary = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df_salary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "112660c0-c651-417d-836e-fb442d9c3be3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_salary.withColumn('sex',\n",
    "                     when(col('sex') == 'f', 'm')\\\n",
    "                         .when(col('sex') == 'm', 'f')).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb2d38c4-ee2a-459d-83c6-9e56d331285a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1050. Actors and Directors Who Cooperated At Least Three Times\n",
    "\n",
    "Write a solution to find all the pairs (actor_id, director_id) where the actor has cooperated with the director at least three times.\n",
    "Return the result table in any order.\n",
    "The result format is in the following example.\n",
    "\n",
    "### Input: ActorDirector Table\n",
    "| actor_id  | director_id | timestamp |\n",
    "|-----------|------------|-----------|\n",
    "| 1         | 1          | 0         |\n",
    "| 1         | 1          | 1         |\n",
    "| 1         | 1          | 2         |\n",
    "| 1         | 2          | 3         |\n",
    "| 1         | 2          | 4         |\n",
    "| 2         | 1          | 5         |\n",
    "| 2         | 1          | 6         |\n",
    "\n",
    "### Output: ActorDirector Table (Most Frequent Pair)\n",
    "| actor_id  | director_id |\n",
    "|-----------|------------|\n",
    "| 1         | 1          |\n",
    "\n",
    "**Explanation**: The only pair is (1, 1) where they cooperated exactly 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "210516bf-cb01-4a6e-ba40-02f1e1db2ed1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Schema\n",
    "schema = StructType([\n",
    "    StructField(\"actor_id\", IntegerType(), True),\n",
    "    StructField(\"director_id\", IntegerType(), True),\n",
    "    StructField(\"timestamp\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create Data\n",
    "data = [\n",
    "    (1, 1, 0),\n",
    "    (1, 1, 1),\n",
    "    (1, 1, 2),\n",
    "    (1, 2, 3),\n",
    "    (1, 2, 4),\n",
    "    (2, 1, 5),\n",
    "    (2, 1, 6)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_actor_director = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df_actor_director.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea58e35c-8ff8-4cfe-95b8-c822423bca04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_actor_director.groupBy('actor_id', 'director_id').agg(count('*').alias('count')).select('actor_id', 'director_id').filter(col('count') == 3).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0a0785d-085c-4675-8cf2-8c5999d1be06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Leetcode(Easy)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
